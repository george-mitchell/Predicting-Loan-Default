{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Loan Default 3 - Models\n",
    "\n",
    "In this notebook we perform model fitting, evaluation and selection. \n",
    "\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data handling \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import polars as pl \n",
    "import polars.selectors as cs\n",
    "\n",
    "## tuning\n",
    "import optuna \n",
    "\n",
    "## visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "## sklearn models\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## pickle \n",
    "from pickle import dump, load\n",
    "\n",
    "## get file path of the data\n",
    "from private import FINAL_FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load file\n",
    "loans_df = pl.read_csv(FINAL_FILE_PATH, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We now split the data into train-test sets and apply our ML models. \n",
    "\n",
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loans_df.to_pandas()\n",
    "y = X.pop(\"default\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization \n",
    "\n",
    "We now normalize the training set and fit the scaling to the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_cols = [\"loan_amnt\", \"int_rate\", \"installment\", \"dti\",\n",
    "                \"fico_range_low\", \"fico_range_high\", \"open_acc\",\n",
    "                \"pub_rec\", \"revol_util\", \"total_acc\", \"last_pymnt_amnt\",\n",
    "                \"acc_open_past_24mths\", \"avg_cur_bal\", \"bc_open_to_buy\",\n",
    "                \"bc_util\", \"mo_sin_old_rev_tl_op\", \"num_actv_rev_tl\",\n",
    "                \"log_annual_inc\", \"log_revol_bal\"]\n",
    "\n",
    "scalers = {}\n",
    "for col in scaling_cols:\n",
    "    scaler = StandardScaler()\n",
    "    X_train[col] = scaler.fit_transform(X_train[[col]])\n",
    "    X_test[col] = scaler.transform(X_test[[col]])\n",
    "    scalers[col] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation \n",
    "\n",
    "Due to the imbalanced nature of our `default` feature, we must carefully consider our metric. As false negatives (borrowers who default but who were predicted to not default) are much more costly to investors than false positives (borrowers who don't default but who were predicted to default), we will make use of recall as a metric, as well as the area under the ROC curve. \n",
    "\n",
    "### Model Selection \n",
    "\n",
    "We will use 3-fold cross validation on a large number of models with default parameters. This will help gauge which type of model may be performing best. We will then select the best performing model for hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "## baseline models \n",
    "models.append(('LR', LogisticRegression(max_iter=10000)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "## ensemble models \n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "## boosting models \n",
    "models.append(('GBM', GradientBoostingClassifier()))\n",
    "models.append(('AB', AdaBoostClassifier(algorithm=\"SAMME\")))\n",
    "## neural networks\n",
    "models.append(('NN', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.8733 (0.000579)\n",
      "KNN: 0.8296 (0.000339)\n",
      "CART: 0.8751 (0.000733)\n",
      "NB: 0.8225 (0.000555)\n",
      "RF: 0.8955 (0.000301)\n",
      "GBM: 0.8955 (0.000942)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/anaconda3/envs/DataScience/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/george/anaconda3/envs/DataScience/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/george/anaconda3/envs/DataScience/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.8855 (0.000184)\n",
      "NN: 0.8946 (0.000805)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models :\n",
    "    kfold = StratifiedKFold(n_splits=3)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {round(cv_results.mean(), 4)} ({round(cv_results.std(), 6)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results so they can be loaded later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = {name:result for (name,result) in zip(names,results)}\n",
    "dump(cv_scores, open(\"../models/cv_scores.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = load(open(\"../models/cv_scores.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the results for each model below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': array([0.87297719, 0.8741417 , 0.87285998]),\n",
       " 'KNN': array([0.83000486, 0.82963812, 0.8291772 ]),\n",
       " 'CART': array([0.87453672, 0.87614637, 0.87465313]),\n",
       " 'NB': array([0.82330898, 0.82216876, 0.82209615]),\n",
       " 'RF': array([0.89517998, 0.89591837, 0.89553954]),\n",
       " 'GBM': array([0.89456437, 0.89681179, 0.89523331]),\n",
       " 'AB': array([0.88553551, 0.88576561, 0.88531416]),\n",
       " 'NN': array([0.89514841, 0.89348752, 0.89523647])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
